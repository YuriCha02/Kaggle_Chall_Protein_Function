{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEZnLeOpI80w"
      },
      "source": [
        "## How to Approach\n",
        "\n",
        "- Think like a producer not a consumer\n",
        "- You have to know how to utilize a tool\n",
        "  - Even if you can't understand perfectly\n",
        "- In client's perspective, you have to know how to reduce a cost on their side.\n",
        "- You have to know how to fit where you want to go in a single sentence\n",
        "  - That is business oriented\n",
        "\n",
        "- Compress the concept to keywords\n",
        "  - Then consider for each concept, whether it will be solved in AI, personnel, or by system\n",
        "\n",
        "- Lay down entire procedures in micro-details and consider which area could be automated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8jQD2u2lS7A"
      },
      "source": [
        "## Background\n",
        "\n",
        "This is the project for Section 3 from Code State.\n",
        "\n",
        "The purpose of project is to determine the function of protein.\n",
        "- The function of protein is determined by their structure and their docking site.\n",
        "- Protein is composed of 20 types of amino acids.\n",
        "\n",
        "### Approach\n",
        "Using a proBERT, a NLP model which typically used in classifying text files,\n",
        "\n",
        "### Goal\n",
        "Predict the function of a set of proteins based on their amino acid sequences and other data\n",
        "\n",
        "### Challenges:\n",
        "Protein can have multiple function while interacting with other proteins."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and install necessary libraries"
      ],
      "metadata": {
        "id": "tNGv8uoa1-9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Bio\n",
        "!pip install pyfastx\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install tf\n",
        "!pip install tensorflow-addons\n",
        "!pip install torchmetrics\n",
        "!pip install tf-nightly\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6YK1l5T2HEy",
        "outputId": "2e757a34-e967-4202-c63f-708e023d4822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Bio in /usr/local/lib/python3.10/dist-packages (1.5.9)\n",
            "Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/dist-packages (from Bio) (1.81)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Bio) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Bio) (4.65.0)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.10/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Bio) (1.5.3)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from Bio) (1.6.0)\n",
            "Requirement already satisfied: gprofiler-official in /usr/local/lib/python3.10/dist-packages (from Bio) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->Bio) (1.22.4)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from mygene->Bio) (0.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2022.7.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->Bio) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyfastx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.10/dist-packages (2.14.0.dev20230515)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.8.0)\n",
            "Requirement already satisfied: keras-nightly~=2.14.0.dev in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.14.0.dev2023051507)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.16.0)\n",
            "Requirement already satisfied: tb-nightly~=2.14.0.a in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.14.0a20230514)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly~=2.14.0.dev in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.14.0.dev2023051508)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.14.0.a->tf-nightly) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import pyfastx\n",
        "import Bio\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import datasets\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons.metrics\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchmetrics\n",
        "from google.colab import drive\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchmetrics.classification import MultilabelF1Score, MultilabelAccuracy\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "dOQ511FT1-Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c52e59f-3cbb-41ce-859e-480ba4fa85a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.14.0-dev20230515). \n",
            "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
            "If you encounter a bug, do not file an issue on GitHub.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h8Z2hPphM34"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIK2ye_yg8MJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dda9a3b-73a1-4305-d0b6-d9c0147e398d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_terms = pd.read_csv('/content/drive/MyDrive/cafa-5-protein-function-prediction/Train/train_terms.tsv', sep = '\\t')\n",
        "train_tax = pd.read_csv('/content/drive/MyDrive/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv', sep = '\\t')\n",
        "train_id = np.load('/content/drive/MyDrive/cafa-5-protein-function-prediction/Embedded Data/train_ids.npy')"
      ],
      "metadata": {
        "id": "MpIk9QX32ndK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "v-NepdPXiDIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "  num_labels = 500\n",
        "  batch_size = 8\n",
        "  n_epochs = 10\n",
        "  lr = 0.2"
      ],
      "metadata": {
        "id": "El2fQY1giSVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.num_labels"
      ],
      "metadata": {
        "id": "6rVoYtuKiUBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491a8620-ee0b-45f8-cc56-6c5dd3e06bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmoj8vOTQNZZ"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3NO6Fsw3MAt"
      },
      "outputs": [],
      "source": [
        "# Create a unique label list\n",
        "unique_labels = train_terms.term.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWgDI2z93N-6"
      },
      "outputs": [],
      "source": [
        "# Copy train FASTA to writable directory to build index later\n",
        "#![ ! -f train_sequences.fasta ] && cp ../content/drive/MyDrive/cafa-5-protein-function-prediction/Train/train_sequences.fasta ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr0cto_M4Baj"
      },
      "source": [
        "`! -f` is a base code that check if the file exists and is a regular file.\n",
        "- `!` negates the result of the test\n",
        "\n",
        "In this code, it checks if the file train_sequences.fasta does not exist or is not a regular file and if it doesn’t exist or is not a regular file, it copies the file from …/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta to the current directory.\n",
        "\n",
        "**Currently this code is not needed**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MNF3Pvd3lFt"
      },
      "outputs": [],
      "source": [
        "# This will build an index file\n",
        "train_fasta = pyfastx.Fasta('/content/drive/MyDrive/cafa-5-protein-function-prediction/Train/train_sequences.fasta')\n",
        "test_fasta = pyfastx.Fasta('/content/drive/MyDrive/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB80Wj0c5BCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbedc7a-d94d-494e-bed6-793fea4de7ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Fasta> /content/drive/MyDrive/cafa-5-protein-function-prediction/Train/train_sequences.fasta contains 142246 sequences"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eUMU_Ji5BSQ"
      },
      "outputs": [],
      "source": [
        "# Each fa[x].seq still does a disk queries so we avoid repeating them\n",
        "# This will only make 140k queries instead of 5 millions (99.97% of them are duplicated)\n",
        "seqs = {x: train_fasta[x].seq for x in train_terms['EntryID'].unique()}\n",
        "train_terms['seq'] = train_terms['EntryID'].map(lambda x: seqs[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3WXR3ywfaXK"
      },
      "source": [
        "`seqs = {x: fa[x].seq for x in train['EntryID'].unique()}`\n",
        "- The for x in train['EntryID'].unique() part is a loop that iterates over each unique 'EntryID' value, assigning it to the variable x.\n",
        "- `{x: fa[x].seq}` is a key-value pair in the dictionary seqs. The key is x (the 'EntryID' value), and the value is `fa[x].seq` (the corresponding sequence).\n",
        "  - `fa[x]` accesses the row of the fa dataframe that has an 'EntryID' value equal to x.\n",
        "  - `fa[x].seq` returns the 'seq' value associated with that row.\n",
        "\n",
        "`train['seq'] = train['EntryID'].map(lambda x: seqs[x])`\n",
        "- use the `map()` method to the 'EntryID' column of the train dataframe, and uses a lambda function to look up each 'EntryID' value in the seqs dictionary and return the corresponding sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_dwEtT3ZwC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577dfafa-190f-489a-c358-18f4755a505c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...\n",
              "1          MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...\n",
              "2          MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...\n",
              "3          MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...\n",
              "4          MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...\n",
              "                                 ...                        \n",
              "5363858    MDLIPSFSTETWLLLAISLVLLYLYGTYTHGIFRKLGIPGPTPLPF...\n",
              "5363859    MDLIPSFSTETWLLLAISLVLLYLYGTYTHGIFRKLGIPGPTPLPF...\n",
              "5363860    MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...\n",
              "5363861    MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...\n",
              "5363862    MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...\n",
              "Name: seq, Length: 5363863, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_terms['seq']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKza5urSaq7C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "77e7a39b-aa71-49a5-aa99-1d82653eb5fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EntryID        term aspect  \\\n",
              "5363858  X5L565  GO:0050649    MFO   \n",
              "5363859  X5L565  GO:0016491    MFO   \n",
              "5363860  X5M5N0  GO:0005515    MFO   \n",
              "5363861  X5M5N0  GO:0005488    MFO   \n",
              "5363862  X5M5N0  GO:0003674    MFO   \n",
              "\n",
              "                                                       seq  \n",
              "5363858  MDLIPSFSTETWLLLAISLVLLYLYGTYTHGIFRKLGIPGPTPLPF...  \n",
              "5363859  MDLIPSFSTETWLLLAISLVLLYLYGTYTHGIFRKLGIPGPTPLPF...  \n",
              "5363860  MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...  \n",
              "5363861  MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...  \n",
              "5363862  MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bf5f210-9112-423d-a910-0f16aae4b14f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EntryID</th>\n",
              "      <th>term</th>\n",
              "      <th>aspect</th>\n",
              "      <th>seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5363858</th>\n",
              "      <td>X5L565</td>\n",
              "      <td>GO:0050649</td>\n",
              "      <td>MFO</td>\n",
              "      <td>MDLIPSFSTETWLLLAISLVLLYLYGTYTHGIFRKLGIPGPTPLPF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5363859</th>\n",
              "      <td>X5L565</td>\n",
              "      <td>GO:0016491</td>\n",
              "      <td>MFO</td>\n",
              "      <td>MDLIPSFSTETWLLLAISLVLLYLYGTYTHGIFRKLGIPGPTPLPF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5363860</th>\n",
              "      <td>X5M5N0</td>\n",
              "      <td>GO:0005515</td>\n",
              "      <td>MFO</td>\n",
              "      <td>MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5363861</th>\n",
              "      <td>X5M5N0</td>\n",
              "      <td>GO:0005488</td>\n",
              "      <td>MFO</td>\n",
              "      <td>MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5363862</th>\n",
              "      <td>X5M5N0</td>\n",
              "      <td>GO:0003674</td>\n",
              "      <td>MFO</td>\n",
              "      <td>MPDSITNGGRPPAPPSSVSSTTASTTGNFGTRRRLVNRIKKVDELH...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bf5f210-9112-423d-a910-0f16aae4b14f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bf5f210-9112-423d-a910-0f16aae4b14f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bf5f210-9112-423d-a910-0f16aae4b14f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_terms.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5-R5MvQLp7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74e1c1b-2814-4c34-e2a8-af054033b9eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31466"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_terms['term'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHVODB2dM9t9"
      },
      "outputs": [],
      "source": [
        "train_terms_selected = train_terms['term'].value_counts()[0: 1500].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhdrihB0RrN0"
      },
      "outputs": [],
      "source": [
        "train_terms = train_terms[train_terms['term'].isin(train_terms_selected)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2jzyoalu3DD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "5735ceb2-d225-463b-c2c2-e9a5ab0d6acb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Check the length distribution of protein sequences\n",
        "\n",
        "train_terms['seq_length'] = train_terms['seq'].apply(len)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(train_terms['seq_length'], bins=50)\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Protein Sequence Length')\n",
        "plt.xlim(0, 6000)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA4US6LHiqht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6bb260-85f1-4fe6-bd67-9435a7cb8485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    4.420737e+06\n",
              "mean     6.327820e+02\n",
              "std      7.695405e+02\n",
              "min      3.000000e+00\n",
              "25%      2.850000e+02\n",
              "50%      4.610000e+02\n",
              "75%      7.470000e+02\n",
              "max      3.537500e+04\n",
              "Name: seq_length, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_terms['seq_length'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6DFIBaRBk1-"
      },
      "source": [
        "## Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwLmfjhpXAWc"
      },
      "outputs": [],
      "source": [
        "#sequence_example = \"MALLHSARVLSGVASAFHPGLAAAASARASSWWAHVEMGPPDPILGVTEAYKRDTNSKKMNLGVGAYRDDNGKPYVLPSVRKAEAQIAAKGLDKEYLPIGGLAEFCRASAELALGENSEVVKSGRFVTVQTISGTGALRIGASFLQRFFKFSRDVFLPKPSWGNHTPIFRDAGMQLQSYRYYDPKTCGFDFTGALEDISKIPEQSVLLLHACAHNPTGVDPRPEQWKEIATVVKKRNLFAFFDMAYQGFASGDGDKDAWAVRHFIEQGINVCLCQSYAKNMGLYGERVGAFTVICKDADEAKRVESQLKILIRPMYSNPPIHGARIASTILTSPDLRKQWLQEVKGMADRIIGMRTQLVSNLKKEGSTHSWQHITDQIGMFCFTGLKPEQVERLTKEFSIYMTKDGRISVAGVTSGNVGYLAHAIHQVTK\"\n",
        "#( len(sequence_example) )\n",
        "\n",
        "#sequence_example = ' '.join(list(sequence_example)) # The tokenizer of prot_bert only accept white space splitted sequence.\n",
        "#print(len(sequence_example))\n",
        "#print((sequence_example))\n",
        "\n",
        "#encoded_input = tokenizer(sequence_example, return_tensors='pt')\n",
        "#output = model(**encoded_input)\n",
        "#type(output) , output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attempt 4"
      ],
      "metadata": {
        "id": "AJfmqvLc0y1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "def tokenize(sequences, length_limit):\n",
        "  output = ' '.join(list(sequences))\n",
        "  encoded_output = tokenizer(output, return_tensors='pt', padding='max_length', truncation=True, max_length = length_limit).to(device)\n",
        "  return encoded_output\n",
        "```"
      ],
      "metadata": {
        "id": "gxjZkRcP1sB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "def embedding(encoded_input):\n",
        "  output = model(**encoded_input)\n",
        "  output_hidden = output['last_hidden_state'][:,0][0].detach().cpu().numpy()\n",
        "  assert len(output_hidden)==1024\n",
        "  return output\n",
        "```"
      ],
      "metadata": {
        "id": "hfEV8bF21x-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def process_data(data):\n",
        "  bert_embedded_vector = []\n",
        "  checkpoint = 0\n",
        "  ids_list = []\n",
        "  df = pd.DataFrame(columns=[\"function_id\", \"bert_embedded_vector\"])\n",
        "  for item in data:\n",
        "    ids_list.append(item.id)\n",
        "    encoded_data = tokenize(sequences = item, length_limit = 1200)\n",
        "    vectorized_data = embedding(encoded_data)\n",
        "    bert_embedded_vector.append(vectorized_data)\n",
        "    checkpoint+=1\n",
        "    if checkpoint>=100:\n",
        "      df_batch = pd.DataFrame(data={\"id\" : ids_list, \"bert_embedded_vector\": bert_embedded_vector})\n",
        "      np.save('/content/drive/MyDrive/cafa-5-protein-function-prediction/train_ids.npy',np.array(ids_list))\n",
        "      np.save('/content/drive/MyDrive/cafa-5-protein-function-prediction/train_embeddings.npy',np.array(bert_embedded_vector))\n",
        "      df = pd.concat([df, df_batch], ignore_index=True)\n",
        "      checkpoint = 0\n",
        "  return df\n",
        "```"
      ],
      "metadata": {
        "id": "1RHeRY9N10Uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "train_df = process_data(train_fasta)\n",
        "```"
      ],
      "metadata": {
        "id": "7RfQfSra1297"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Code"
      ],
      "metadata": {
        "id": "tUQsxRX10uhm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P056mvwyR6Hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7101db9d-15db-485b-cff5-1c5bfdc4c1a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
        "model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "````\n",
        "def get_bert_embedding(model, tokenizer, sequence, len_seq_limit):\n",
        "    sequence_w_spaces = ' '.join(list(sequence))\n",
        "    encoded_input = tokenizer.encode_plus(\n",
        "        sequence_w_spaces,\n",
        "        truncation=True,\n",
        "        max_length=len_seq_limit,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "    output_hidden = output.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
        "    assert output_hidden.shape[1] == 1024\n",
        "    return output_hidden[0]\n",
        "\n",
        "def process_sequences(sequences_path, output_dir, model, tokenizer, len_seq_limit):\n",
        "    fasta_sequences = SeqIO.parse(sequences_path, \"fasta\")\n",
        "    ids_list = []\n",
        "    embed_vects_list = []\n",
        "    t0 = time.time()\n",
        "    checkpoint = 0\n",
        "    for item in fasta_sequences:\n",
        "        ids_list.append(item.id)\n",
        "        embed_vects_list.append(\n",
        "            get_bert_embedding(model, tokenizer, sequence=item.seq, len_seq_limit=len_seq_limit)\n",
        "        )\n",
        "        checkpoint += 1\n",
        "        if checkpoint >= 100:\n",
        "            df_res = pd.DataFrame(data={\"id\": ids_list, \"embed_vect\": embed_vects_list})\n",
        "            np.save(os.path.join(output_dir, \"ids.npy\"), np.array(ids_list))\n",
        "            np.save(os.path.join(output_dir, \"embeddings.npy\"), np.array(embed_vects_list))\n",
        "            checkpoint = 0\n",
        "\n",
        "    np.save(os.path.join(output_dir, \"ids.npy\"), np.array(ids_list))\n",
        "    np.save(os.path.join(output_dir, \"embeddings.npy\"), np.array(embed_vects_list))\n",
        "    print('Total Elapsed Time:', time.time() - t0)\n",
        "````"
      ],
      "metadata": {
        "id": "wCLAFZZp1mHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "````\n",
        "# Process train set sequences\n",
        "process_sequences(\n",
        "    sequences_path=\"/content/drive/MyDrive/cafa-5-protein-function-prediction/Train/train_sequences.fasta\",\n",
        "    output_dir='/content/drive/MyDrive/cafa-5-protein-function-prediction/train/',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    len_seq_limit=1200\n",
        ")\n",
        "````"
      ],
      "metadata": {
        "id": "zOtRLLDZ1oT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "````\n",
        "# Process test set sequences\n",
        "process_sequences(\n",
        "    sequences_path=\"/content/drive/MyDrive/cafa-5-protein-function-prediction/Test (Targets)/test_sequences.fasta\",\n",
        "    output_dir='/content/drive/MyDrive/cafa-5-protein-function-prediction/test/',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    len_seq_limit=1200\n",
        ")\n",
        "````"
      ],
      "metadata": {
        "id": "jXCqfCTwDQ-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label train/test"
      ],
      "metadata": {
        "id": "smDHA3kS4BQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "def label_most_frequent_sequences(ids, labels):\n",
        "  top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
        "  labels_names = top_terms[:config.num_labels].index.values\n",
        "  train_labels_sub = labels[(labels.term.isin(labels_names)) & (labels.EntryID.isin(ids))]\n",
        "  id_labels = train_labels_sub.groupby('EntryID')['term'].apply(list).to_dict()\n",
        "  go_terms_map = {label: i for i, label in enumerate(labels_names)}\n",
        "  labels_matrix = np.empty((len(ids), len(labels_names)))\n",
        "  for index, id in enumerate(ids):\n",
        "    id_gos_list = id_labels[id]\n",
        "    temp = [go_terms_map[go] for go in labels_names if go in id_gos_list]\n",
        "    labels_matrix[index, temp] = 1\n",
        "  np.save('/content/drive/MyDrive/cafa-5-protein-function-prediction/Embedded Data/train_top' + str(config.num_labels) +'_labeled_sequence.npy', np.array(labels_matrix))\n",
        "```"
      ],
      "metadata": {
        "id": "dXspGColhNj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "def label_most_frequent_sequences(ids, labels):\n",
        "  top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
        "  labels_names = top_terms[:config.num_labels].index.values\n",
        "  train_labels_sub = labels[(labels.term.isin(labels_names)) & (labels.EntryID.isin(ids))]\n",
        "  id_labels = train_labels_sub.groupby('EntryID')['term'].apply(list).to_dict()\n",
        "  go_terms_map = {label: i for i, label in enumerate(labels_names)}\n",
        "  labels_matrix = np.empty((len(ids), len(labels_names)))\n",
        "  for index, id in enumerate(ids):\n",
        "    id_gos_list = id_labels[id]\n",
        "    temp = [go_terms_map[go] for go in labels_names if go in id_gos_list]\n",
        "    labels_matrix[index, temp] = 1\n",
        "  np.save('/content/drive/MyDrive/cafa-5-protein-function-prediction/Embedded Data/train_top' + str(config.num_labels) +'_labeled_sequence.npy', np.array(labels_matrix))\n",
        "\n",
        "label_most_frequent_sequences(ids = train_id, labels = train_terms)\n",
        "```"
      ],
      "metadata": {
        "id": "eFPaco9mhRo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "YhZlG-n_FzLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeds = np.load(\"/content/drive/MyDrive/cafa-5-protein-function-prediction/Embedded Data/train_embeddings.npy\")\n",
        "train_ids = np.load(\"/content/drive/MyDrive/cafa-5-protein-function-prediction/Embedded Data/train_ids.npy\")\n",
        "train_labels = np.load('/content/drive/MyDrive/cafa-5-protein-function-prediction/Embedded Data/train_top' + str(config.num_labels) +'_labeled_sequence.npy')"
      ],
      "metadata": {
        "id": "cDTKbKQH-AvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib1s_-zgFQml",
        "outputId": "d1c524ec-514f-402a-fe62-ae658ec858cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 1., 1.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeds_list = []\n",
        "for l in range(train_embeds.shape[0]):\n",
        "  embeds_list.append(train_embeds[l, :])\n",
        "\n",
        "labels_df = pd.DataFrame(train_labels, columns=range(train_labels.shape[1]))\n",
        "\n",
        "train_df = pd.DataFrame(data={\"EntryID\": train_ids, \"embed\": embeds_list})\n",
        "train_df = pd.concat([train_df, labels_df], axis=1)"
      ],
      "metadata": {
        "id": "4NxayHBYTA1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "3PpqahbhFIRr",
        "outputId": "4e8ce90b-ac03-41df-bb69-8ecfb375479e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
              "0       0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
              "1       1.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
              "2       1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  ...  0.0  0.0  0.0   \n",
              "3       1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
              "4       1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  ...  0.0  0.0  0.0   \n",
              "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "142241  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "142242  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "142243  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "142244  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
              "142245  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  1.0  0.0   \n",
              "\n",
              "        493  494  495  496  497  498  499  \n",
              "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1       0.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
              "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4       0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "...     ...  ...  ...  ...  ...  ...  ...  \n",
              "142241  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "142242  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "142243  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "142244  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "142245  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[142246 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddfe614e-1dcd-4550-9666-5479717875f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142241</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142242</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142243</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142244</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142245</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>142246 rows × 500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddfe614e-1dcd-4550-9666-5479717875f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddfe614e-1dcd-4550-9666-5479717875f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddfe614e-1dcd-4550-9666-5479717875f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a model"
      ],
      "metadata": {
        "id": "RRF45joBwvm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(CNN1D, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, dilation=1, padding='same')\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, dilation=1, padding='same')\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, dilation=1, padding='same')\n",
        "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(input_dim // 8 * 64, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool3(F.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        logits = self.fc3(x)\n",
        "        return logits\n",
        "\n",
        "def train_model(train_embed, train_labels, val_embed, val_labels, config):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    train_embed = torch.tensor(train_embed, dtype=torch.float32)\n",
        "    train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
        "    val_embed = torch.tensor(val_embed, dtype=torch.float32)\n",
        "    val_labels = torch.tensor(val_labels, dtype=torch.float32)\n",
        "\n",
        "    train_dataset = TensorDataset(train_embed, train_labels)\n",
        "    val_dataset = TensorDataset(val_embed, val_labels)\n",
        "\n",
        "    train_size = len(train_dataset)\n",
        "    val_size = len(val_dataset)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=config.batch_size)\n",
        "\n",
        "    model = CNN1D(input_dim=1024, num_classes=config.num_labels).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=1)\n",
        "    metric1 = MultilabelF1Score(num_labels=config.num_labels, average='macro')\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    n_epochs = config.n_epochs\n",
        "\n",
        "    print(\"BEGIN TRAINING...\")\n",
        "    train_metric1_history = []\n",
        "    train_loss_history = []\n",
        "    val_metric1_history = []\n",
        "    val_loss_history = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"EPOCH \", epoch+1)\n",
        "        ## TRAIN PHASE :\n",
        "        model.train()\n",
        "        train_metrics1 = []\n",
        "        train_losses = []\n",
        "\n",
        "        for embed, targets in train_dataloader:\n",
        "            embed, targets = embed.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(embed)\n",
        "            loss_value = loss_fn(logits, targets)\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_metrics1.append(metric1(torch.sigmoid(logits), targets).detach().cpu().numpy())\n",
        "            train_losses.append(loss_value.item())\n",
        "\n",
        "        avg_train_metric1 = np.mean(train_metrics1)\n",
        "        avg_train_loss = np.mean(train_losses)\n",
        "        print(\"Running Average TRAIN F1 Score : \", avg_train_metric1)\n",
        "        print(\"Running Average TRAIN Loss : \", avg_train_loss)\n",
        "        train_metric1_history.append(avg_train_metric1)\n",
        "        train_loss_history.append(avg_train_loss)\n",
        "\n",
        "        ## VALIDATION PHASE :\n",
        "        model.eval()\n",
        "        val_metrics1 = []\n",
        "        val_losses = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for embed, targets in val_dataloader:\n",
        "                embed, targets = embed.to(device), targets.to(device)\n",
        "                logits = model(embed)\n",
        "                loss_value = loss_fn(logits, targets)\n",
        "\n",
        "                val_metrics1.append(metric1(torch.sigmoid(logits), targets).detach().cpu().numpy())\n",
        "                val_losses.append(loss_value.item())\n",
        "\n",
        "        avg_val_metric1 = np.mean(val_metrics1)\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        print(\"Running Average VAL F1 Score : \", avg_val_metric1)\n",
        "        print(\"Running Average VAL Loss : \", avg_val_loss)\n",
        "        val_metric1_history.append(avg_val_metric1)\n",
        "        val_loss_history.append(avg_val_loss)\n",
        "\n",
        "        scheduler.step(avg_val_metric1)\n",
        "\n",
        "    print(\"TRAINING FINISHED\")\n",
        "    print(\"FINAL TRAINING\")\n",
        "\n",
        "    metrics_history = {\"train_f1_score\": train_metric1_history, \"train_loss\": train_loss_history,\n",
        "                       \"val_f1_score\": val_metric1_history, \"val_loss\": val_loss_history}\n",
        "\n",
        "    return model, metrics_history\n"
      ],
      "metadata": {
        "id": "XxEK2cs7xZYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "vitx1VSDKtto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "train_data, val_data = train_test_split(train_df, test_size=0.25, random_state=42)\n",
        "\n",
        "# Convert the input data and labels to NumPy arrays\n",
        "train_embed = np.array(train_data[\"embed\"].tolist())\n",
        "train_labels = np.array(train_data.drop([\"EntryID\", \"embed\"], axis=1))\n",
        "\n",
        "val_embed = np.array(val_data[\"embed\"].tolist())\n",
        "val_labels = np.array(val_data.drop([\"EntryID\", \"embed\"], axis=1))"
      ],
      "metadata": {
        "id": "uY4Wjk48Kv-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsRutd2cFD5r",
        "outputId": "9fd8df8f-c29b-4e82-97af-eb5f94a4c22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 1., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 1., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, metrics_history = train_model(train_embed, train_labels, val_embed, val_labels, config)"
      ],
      "metadata": {
        "id": "oWeHtDOP9VR6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "outputId": "a40113d8-0831-48b9-d2b6-9deddc25280e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEGIN TRAINING...\n",
            "EPOCH  1\n",
            "Running Average TRAIN F1 Score :  0.0069602057\n",
            "Running Average TRAIN Loss :  0.5698480818132369\n",
            "Running Average VAL F1 Score :  0.008162505\n",
            "Running Average VAL Loss :  0.16720495131193547\n",
            "EPOCH  2\n",
            "Running Average TRAIN F1 Score :  0.0069087096\n",
            "Running Average TRAIN Loss :  0.1673099726268683\n",
            "Running Average VAL F1 Score :  0.008391905\n",
            "Running Average VAL Loss :  0.1680965070259555\n",
            "EPOCH  3\n",
            "Running Average TRAIN F1 Score :  0.006896006\n",
            "Running Average TRAIN Loss :  0.16732167077307206\n",
            "Running Average VAL F1 Score :  0.0060049375\n",
            "Running Average VAL Loss :  0.16732695289844335\n",
            "EPOCH  4\n",
            "Running Average TRAIN F1 Score :  0.0069229337\n",
            "Running Average TRAIN Loss :  0.16730288166081256\n",
            "Running Average VAL F1 Score :  0.0060049375\n",
            "Running Average VAL Loss :  0.16618377812042517\n",
            "EPOCH  5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4e06f58b7717>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-00ecf9cd3288>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_embed, train_labels, val_embed, val_labels, config)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mtrain_metrics1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 state_steps)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    282\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "AJfmqvLc0y1x"
      ],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
